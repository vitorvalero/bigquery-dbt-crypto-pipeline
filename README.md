# ğŸš€ Binance Crypto Pipeline - ELT com Airflow, BigQuery e DBT

![Badge](https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow?style=for-the-badge)
![Badge](https://img.shields.io/badge/VersÃ£o-0.1-blue?style=for-the-badge)

## ğŸ“Œ Sobre o Projeto

Este Ã© um projeto autoral de desenvolvimento de **pipeline de ELT (Extract, Load, Transform)** para coletar dados de trading da **API da Binance**, armazenar no **GCS**, carregar no **BigQuery**, e visualizar no **Metabase**. O objetivo Ã© criar uma soluÃ§Ã£o robusta e escalÃ¡vel para anÃ¡lise de dados do mercado de criptomoedas.

A estrutura do projeto foi elaborada do zero, bem como seu planejamento, arquitetura e implementaÃ§Ã£o. NÃ£o houve uso de repositÃ³rios clonados, apenas de templates de arquivos de configuraÃ§Ã£o **Docker Compose** de fontes oficiais para garantir o bom funcionamento e gerenciamento dos containers **Docker**.

---

## ğŸ›  Tecnologias Utilizadas

- **Fonte dos Dados**: [Binance API](https://api.binance.com)
- **OrquestraÃ§Ã£o**: [Apache Airflow](https://airflow.apache.org/)
- **Armazenamento**: [Google Cloud Storage (GCS)](https://cloud.google.com/storage)
- **Data Warehouse**: [Google BigQuery](https://cloud.google.com/bigquery)
- **TransformaÃ§Ã£o (futuro)**: [DBT](https://www.getdbt.com/)
- **VisualizaÃ§Ã£o**: [Metabase](https://www.metabase.com/)
- **Infraestrutura**: [Docker](https://www.docker.com/) + [Docker Compose](https://docs.docker.com/compose/)

---

## ğŸš§ Status do Projeto

âš  **O projeto ainda estÃ¡ em construÃ§Ã£o!** AtÃ© agora, foram configurados os seguintes componentes:

- âœ… **Airflow** - OrquestraÃ§Ã£o das DAGs de extraÃ§Ã£o e carga de dados.
- âœ… **Google Cloud Storage (GCS)** - Armazenamento dos arquivos em formato Parquet.
- âœ… **BigQuery** - Armazenamento e estruturaÃ§Ã£o dos dados como Data Warehouse.
- âœ… **Metabase** - VisualizaÃ§Ã£o inicial dos dados diretamente do BigQuery.

---

## ğŸ— Arquitetura do Projeto

1. **ExtraÃ§Ã£o de Dados**: DAGs no **Airflow** fazem chamadas Ã  API da **Binance** para obter dados de mercado.
2. **Armazenamento**: Os dados brutos sÃ£o armazenados no **Google Cloud Storage (GCS)** em formato **Parquet**.
3. **Carga no BigQuery**: DAGs no **Airflow** carregam os arquivos Parquet no **BigQuery**.
4. **TransformaÃ§Ã£o (em desenvolvimento)**: **DBT** serÃ¡ usado para modelagem e agregaÃ§Ã£o dos dados.
5. **VisualizaÃ§Ã£o (em desenvolvimento)**: **Metabase** consome os dados diretamente do **BigQuery** para criar dashboards interativos.

---

## ğŸ—‚ Estrutura do Projeto

- **ğŸ“‚ airflow/** â†’ ConfiguraÃ§Ã£o do Airflow e DAGs do pipeline.  
- **ğŸ“‚ dags/** â†’ DAGs do Airflow para extraÃ§Ã£o e carga de dados.  
  - **ğŸ“‚ dags/tasks/** â†’ Tarefas individuais que compÃµem as DAGs.  
  - **ğŸ“‚ dags/utils/** â†’ FunÃ§Ãµes auxiliares para extraÃ§Ã£o e transformaÃ§Ã£o.  
- **ğŸ“‚ dbt/** â†’ (Futuro) DiretÃ³rio reservado para os modelos do DBT.  
- **ğŸ“‚ metabase/** â†’ ConfiguraÃ§Ã£o do Metabase para visualizaÃ§Ã£o de dados.  
- **ğŸ“‚ scripts/** â†’ Scripts para ligar/desligar serviÃ§os.  

---

## ğŸ”œ PrÃ³ximos Desenvolvimentos

Este projeto estÃ¡ em constante evoluÃ§Ã£o. As prÃ³ximas etapas incluirÃ£o:

- **ImplementaÃ§Ã£o do DBT** para transformaÃ§Ã£o de dados no BigQuery.
- **CriaÃ§Ã£o de modelos analÃ­ticos e agregaÃ§Ãµes** para otimizar consultas.
- **Desenvolvimento dos dashboards no Metabase** para visualizaÃ§Ã£o e insights mais detalhados.
- **OtimizaÃ§Ã£o das DAGs do Airflow** para melhorar a eficiÃªncia do pipeline.
- **DocumentaÃ§Ã£o detalhada das transformaÃ§Ãµes e arquitetura final**.

Fique atento para futuras atualizaÃ§Ãµes! ğŸš€
